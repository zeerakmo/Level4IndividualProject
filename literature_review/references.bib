@article{Redmon2016,
abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.},
archivePrefix = {arXiv},
arxivId = {arXiv:1506.02640v5},
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
doi = {10.1109/CVPR.2016.91},
eprint = {arXiv:1506.02640v5},
file = {:C$\backslash$:/Users/zeera/Downloads/1506.02640.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {779--788},
title = {{You only look once: Unified, real-time object detection}},
volume = {2016-Decem},
year = {2016}
}
@inproceedings{Yang2016,
abstract = {Face detection is one of the most studied topics in the computer vision community. Much of the progresses have been made by the availability of face detection benchmark datasets. We show that there is a gap between current face detection performance and the real world requirements. To facilitate future face detection research, we introduce the WIDER FACE dataset1, which is 10 times larger than existing datasets. The dataset contains rich annotations, including occlusions, poses, event categories, and face bounding boxes. Faces in the proposed dataset are extremely challenging due to large variations in scale, pose and occlusion, as shown in Fig. 1. Furthermore, we show that WIDER FACE dataset is an effective training source for face detection. We benchmark several representative detection systems, providing an overview of state-of-the-art performance and propose a solution to deal with large scale variation. Finally, we discuss common failure cases that worth to be further investigated.},
archivePrefix = {arXiv},
arxivId = {1511.06523},
author = {Yang, Shuo and Luo, Ping and Loy, Chen Change and Tang, Xiaoou},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2016.596},
eprint = {1511.06523},
isbn = {9781467388504},
issn = {10636919},
title = {{WIDER FACE: A face detection benchmark}},
year = {2016}
}
@article{Naveenkumar2016,
author = {Naveenkumar, M},
file = {:C$\backslash$:/Users/zeera/Downloads/NCBDC2{\_}126 (1).pdf:pdf},
keywords = {edge detection,face,image processing,opencv},
number = {March 2015},
pages = {52--56},
title = {{OpenCV for Computer Vision Applications}},
year = {2016}
}
@article{Culjak2012,
abstract = {The purpose of this paper is to introduce and quickly make a reader familiar with OpenCV (Open Source Computer Vision) basics without having to go through the lengthy reference manuals and books. OpenCV is an open source library for image and video analysis, originally introduced more than decade ago by Intel. Since then, a number of programmers have contributed to the most recent library developments. The latest major change took place in 2009 (OpenCV 2) which includes main changes to the C++ interface. Nowadays the library has {\textgreater}2500 optimized algorithms. It is extensively used around the world, having {\textgreater}2.5M downloads and {\textgreater}40K people in the user group. Regardless of whether one is a novice C++ programmer or a professional software developer, unaware of OpenCV, the main library content should be interesting for the graduate students and researchers in image processing and computer vision areas. To master every library element it is necessary to consult many books available on the topic of OpenCV. However, reading such more comprehensive material should be easier after comprehending some basics about OpenCV from this paper. {\textcopyright} 2012 MIPRO.},
author = {Culjak, Ivan and Abram, David and Pribanic, Tomislav and Dzapo, Hrvoje and Cifrek, Mario},
file = {:C$\backslash$:/Users/zeera/Downloads/sp{\_}008.pdf:pdf},
isbn = {9789532330724},
journal = {MIPRO 2012 - 35th International Convention on Information and Communication Technology, Electronics and Microelectronics - Proceedings},
pages = {1725--1730},
title = {{A brief introduction to OpenCV}},
year = {2012}
}
@article{Sagonas2013,
abstract = {Automatic facial point detection plays arguably the most important role in face analysis. Several methods have been proposed which reported their results on databases of both constrained and unconstrained conditions. Most of these databases provide annotations with different mark-ups and in some cases the are problems related to the accuracy of the fiducial points. The aforementioned issues as well as the lack of a evaluation protocol makes it difficult to compare performance between different systems. In this paper, we present the 300 Faces in-the-Wild Challenge: The first facial landmark localization Challenge which is held in conjunction with the International Conference on Computer Vision 2013, Sydney, Australia. The main goal of this challenge is to compare the performance of different methods on a new-collected dataset using the same evaluation protocol and the same mark-up and hence to develop the first standardized benchmark for facial landmark localization. {\textcopyright} 2013 IEEE.},
author = {Sagonas, Christos and Tzimiropoulos, Georgios and Zafeiriou, Stefanos and Pantic, Maja},
doi = {10.1109/ICCVW.2013.59},
file = {:C$\backslash$:/Users/zeera/Downloads/sagonas{\_}iccv{\_}2013{\_}300{\_}w.pdf:pdf},
isbn = {9781479930227},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {397--403},
title = {{300 faces in-the-wild challenge: The first facial landmark Localization Challenge}},
year = {2013}
}
@article{Ma2015,
abstract = {Researchers studying a range of psychological phenomena (e.g., theory of mind, emotion, stereotyping and prejudice, interpersonal attraction, etc.) sometimes employ photographs of people as stimuli. In this paper, we introduce the Chicago Face Database, a free resource consisting of 158 high-resolution, standardized photographs of Black and White males and females between the ages of 18 and 40Â years and extensive data about these targets. In Study 1, we report pre-testing of these faces, which includes both subjective norming data and objective physical measurements of the images included in the database. In Study 2 we surveyed psychology researchers to assess the suitability of these targets for research purposes and explored factors that were associated with researchers' judgments of suitability. Instructions are outlined for those interested in obtaining access to the stimulus set and accompanying ratings and measures.},
author = {Ma, Debbie S. and Correll, Joshua and Wittenbrink, Bernd},
doi = {10.3758/s13428-014-0532-5},
file = {:C$\backslash$:/Users/zeera/Downloads/Ma2015{\_}Article{\_}TheChicagoFaceDatabaseAFreeSti.pdf:pdf},
isbn = {1342801405325},
issn = {15543528},
journal = {Behavior Research Methods},
keywords = {Face database,Multiracial faces,Normed face stimuli},
number = {4},
pages = {1122--1135},
pmid = {25582810},
title = {{The Chicago face database: A free stimulus set of faces and norming data}},
volume = {47},
year = {2015}
}
@article{Johnston2018,
abstract = {The accurate identification of landmarks within facial images is an important step in the completion of a number of higher-order computer vision tasks such as facial recognition and facial expression analysis. While being an intuitive and simple task for human vision, it has taken decades of research, an increase in the availability of quality data sets, and a dramatic improvement in computational processing power to achieve near-human accuracy in landmark localisation. The intent of this paper is to provide a review of the current facial landmarking literature, outlining the significant progress that has been made in the field from classical generative methods to more modern techniques such as sophisticated deep neural network architectures. This review considers a generalised facial landmarking problem and provides experimental examples for each stage in the process, reporting repeatable benchmarks across a number of publicly available datasets and linking the results of these examples to the recently reported performance in the literature.},
author = {Johnston, Benjamin and de Chazal, Philip},
doi = {10.1186/s13640-018-0324-4},
file = {:C$\backslash$:/Users/zeera/Downloads/Johnston-Chazal2018{\_}Article{\_}AReviewOfImage-basedAutomaticF (2).pdf:pdf},
isbn = {1364001803244},
issn = {16875281},
journal = {Eurasip Journal on Image and Video Processing},
keywords = {Artificial neural networks,Deep learning,Face,Image,Landmarking,Machine learning,Registration,Review,Survey,Vision},
number = {1},
publisher = {EURASIP Journal on Image and Video Processing},
title = {{A review of image-based automatic facial landmark identification techniques}},
volume = {2018},
year = {2018}
}
@article{Ren2017,
abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features - using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3], our detection system has a frame rate of 5 fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.},
archivePrefix = {arXiv},
arxivId = {1506.01497},
author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
doi = {10.1109/TPAMI.2016.2577031},
eprint = {1506.01497},
file = {:C$\backslash$:/Users/zeera/Downloads/1506.01497.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Object detection,convolutional neural network,region proposal},
number = {6},
pages = {1137--1149},
pmid = {27295650},
title = {{Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}},
volume = {39},
year = {2017}
}
@article{Loy2020,
abstract = {In recent years, face recognition has attracted much attention and its research has rapidly expanded by not only engineers but also neuroscientists, since it has many potential applications in computer vision},
author = {Loy, Chen Change},
doi = {10.1007/978-3-030-03243-2_798-1},
file = {:C$\backslash$:/Users/zeera/Downloads/Loy2020{\_}ReferenceWorkEntry{\_}FaceDetection.pdf:pdf},
isbn = {9783030032432},
journal = {Computer Vision},
pages = {1--5},
title = {{Face Detection}},
year = {2020}
}
@article{Beumer2005,
abstract = {Good registration (alignment to a reference) is essential for accurate face recognition. We use the locations of facial features (eyes, nose, mouth, etc) as landmarks for registration. Two landmarking methods are explored and compared: (1) the Most Likely-Landmark Locator (MLLL), based on maximizing the likelihood ratio [1], and (2) Viola- Jones detection [2]. Further, a landmark-correction method based on projection into a subspace is introduced. Both landmarking methods have been trained on the landmarked images in the BioID database [3]. The MLLL has been trained for locating 17 landmarks and the Viola- Jones method for 5 landmarks. The localization error and effects on the equal-error rate (EER) have been measured. In these experiments ground- truth data has been used as a reference. The results are described as follows: 1. The localization errors obtained on the FRGC database are 4.2, 8.6 and 4.6 pixels for the Viola-Jones, the MLLL, and the MLLL after landmark correction, respectively. The inter-eye distance of the reference face is 100 pixels. The MLLL with landmark correction scores best in the verifica- tion experiment. 2. Using more landmarks decreases the average localization error and the EER.},
author = {Beumer, GM and Tao, Q. and Bazen, AM and Veldhuis, RNJ},
file = {:C$\backslash$:/Users/zeera/Downloads/Beumer05comparing.pdf:pdf},
journal = {Proceedings of the 16th ProRISC workshop on Circuits, Systems and Signal Processing},
keywords = {face recognition,face registration,facial feature,landmark,landmarking,likelihood ratio,viola-jones},
number = {1},
pages = {594--597},
title = {{Comparing landmarking methods for face recognition}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Comparing+landmarking+methods+for+face+recognition{\#}0},
year = {2005}
}
@article{An2017,
abstract = {Currently face detection method is becoming a more and more important technique in our social lives. From face detection technology implemented in our cheap cameras to intelligent agencies' sophisticated global skynet surveillance system, such techniques have been widely used in a large number of areas and the market is still growing with a high speed. Face detection has been an active research area with many successful traditional and deep learning methods. In our project we are introducing new convolutional neural network method to tackle the face detection to maintain a high accuracy while running in real time.},
author = {An, Yicheng and Wu, Jiafu and Yue, Chang},
file = {:C$\backslash$:/Users/zeera/Downloads/222.pdf:pdf},
title = {{CNNs for Face Detection and Recognition}},
year = {2017}
}
@article{Popoola2020,
abstract = {Systems and applications embedded with facial detection and recognition capabilities are founded on the notion that there are differences in face structures among individuals, and as such, we can perform face-matching using the facial symmetry. A widely used application of facial detection and recognition is in security. It is important that the images be processed correctly for computer-based facial recognition, hence, the usage of efficient, cost-effective algorithms and a robust database. This research work puts these measures into consideration and attempts to determine a cost-effective and reliable algorithm out of three algorithms examined.
 Keywords: Haar-Cascade, PCA, Eigenfaces, Fisherfaces, LBPH, Face Recognition.},
author = {Popoola, J.A. and Yinka-Banjo, C.O.},
doi = {10.4314/njt.v39i3.31},
file = {:C$\backslash$:/Users/zeera/Downloads/199768-Article Text-501674-1-10-20200916 (1).pdf:pdf},
issn = {0331-8443},
journal = {Nigerian Journal of Technology},
keywords = {eigenfaces,face recognition,fisherfaces,haar-cascade,lbph,pca},
number = {3},
pages = {896--904},
title = {{Comparative analysis of selected facial recognition algorithms}},
volume = {39},
year = {2020}
}
@article{Rahmad2020,
abstract = {Human face recognition is one of the most challenging topics in the areas of image processing, computer vision, and pattern recognition. Before recognizing the human face, it is necessary to detect a face then extract the face features. Many methods have been created and developed in order to perform face detection and two of the most popular methods are Viola-Jones Haar Cascade Classifier (V-J) and Histogram of Oriented Gradients (HOG). This paper proposed a comparison between VJ and HOG for detecting the face. V-J method calculate Integral Image through Haar-like feature with AdaBoost process to make a robust cascade classifier, HOG compute the classifier for each image in and scale of the image, applied the sliding windows, extracted HOG descriptor at each window and applied the classifier, if the classifier detected an object with enough probability that resembles a face, the classifier recording the bounding box of the window and applied non-maximum suppression to make the accuracy increased. The experimental results show that the system successfully detected face based on the determined algorithm. That is mean the application using computer vision can detect face and compare the results.},
author = {Rahmad, C. and Asmara, R. A. and Putra, D. R.H. and Dharma, I. and Darmono, H. and Muhiqqin, I.},
doi = {10.1088/1757-899X/732/1/012038},
file = {:C$\backslash$:/Users/zeera/Downloads/Rahmad{\_}2020{\_}IOP{\_}Conf.{\_}Ser.{\_}{\_}Mater.{\_}Sci.{\_}Eng.{\_}732{\_}012038.pdf:pdf},
issn = {1757899X},
journal = {IOP Conference Series: Materials Science and Engineering},
number = {1},
title = {{Comparison of Viola-Jones Haar Cascade Classifier and Histogram of Oriented Gradients (HOG) for face detection}},
volume = {732},
year = {2020}
}
@article{Surasak2018,
abstract = {Currently, Computer Vision (CV) is one of the most popular research topics in the world. This is because it can support the human daily life. Moreover, CV can also apply to various theories and researches. Human Detection is one of the most popular research topics in Computer Vision. In this paper, we present a study of technique for human detection from video, which is the Histograms of Oriented Gradients or HOG by developing a piece of application to import and detect the human from the video. We use the HOG Algorithm to analyze every frame from the video to find and count people. After analyzing video from starting to the end, the program generate histogram to show the number of detected people versus playing period of the video. As a result, the expected results are obtained, including the detection of people in the video and the histogram generation to show the appearance of human detected in the video file.},
author = {Surasak, Thattapon and Takahiro, Ito and Cheng, Cheng Hsuan and Wang, Chi En and Sheng, Pao You},
doi = {10.1109/ICBIR.2018.8391187},
file = {:C$\backslash$:/Users/zeera/Downloads/Dalal-cvpr05.pdf:pdf},
isbn = {9781538652541},
journal = {Proceedings of 2018 5th International Conference on Business and Industrial Research: Smart Technology for Next Generation of Information, Engineering, Business and Social Science, ICBIR 2018},
keywords = {Histogram of Oriented Gradients,Human Detection},
pages = {172--176},
title = {{Histogram of oriented gradients for human detection in video}},
year = {2018}
}
@article{Brown2014,
abstract = {Following requirements in the 1996 EU Energy Efficiency Directive, member states are developing programmes to encourage the installation of 'smart' power meters that record much larger quantities of data about power usage than traditional meters. These data can reveal a great deal of information about individual household activity, leading privacy regulators to call for privacy to be 'designed in' to these systems. The British smart metering programme has given some attention to this privacy by design process. This article assesses its effectiveness in this case, using documentary analysis, participant observation, and follow-up interviews with a range of stakeholders. It finds that decisions made early in the British programme had negative privacy impacts that have only been partially remedied by the later development of detailed rules on the processing of smart meter data by energy suppliers and distributors. The article also considers broader lessons for the privacy by design approach. {\textcopyright} 2013 {\textcopyright} 2013 Taylor {\&} Francis.},
author = {Brown, Ian},
doi = {10.1080/13600869.2013.801580},
file = {:C$\backslash$:/Users/zeera/Downloads/Britain s smart meter programme A case study in privacy by design.pdf:pdf},
issn = {13646885},
journal = {International Review of Law, Computers and Technology},
keywords = {data protection,energy efficiency,technology regulation},
number = {2},
pages = {172--184},
title = {{Britain's smart meter programme: A case study in privacy by design}},
volume = {28},
year = {2014}
}
@inproceedings{Viola2001,
abstract = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "Integral Image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
author = {Viola, Paul and Jones, Michael},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/cvpr.2001.990517},
file = {:C$\backslash$:/Users/zeera/Downloads/viola01rapid.pdf:pdf},
issn = {10636919},
title = {{Rapid object detection using a boosted cascade of simple features}},
year = {2001}
}
@article{Liu2016,
abstract = {We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, COCO, and ILSVRC datasets confirm that SSD has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. For 300Ã300 input, SSD achieves 74.3{\%} mAP on VOC2007 test at 59 FPS on a Nvidia Titan X and for 512 Ã 512 input, SSD achieves 76.9{\%} mAP, outperforming a comparable state of the art Faster R-CNN model. Compared to other single stage methods, SSD has much better accuracy even with a smaller input image size. Code is available at https://github.com/weiliu89/caffe/ tree/ssd.},
archivePrefix = {arXiv},
arxivId = {arXiv:1512.02325v5},
author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng Yang and Berg, Alexander C.},
doi = {10.1007/978-3-319-46448-0_2},
eprint = {arXiv:1512.02325v5},
file = {:C$\backslash$:/Users/zeera/Downloads/1512.02325.pdf:pdf},
isbn = {9783319464473},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Convolutional neural network,Real-time object detection},
pages = {21--37},
title = {{SSD: Single shot multibox detector}},
volume = {9905 LNCS},
year = {2016}
}
@article{Singh2020,
abstract = {Face recognition algorithms have demonstrated very high recognition performance, suggesting suitability for real world applications. Despite the enhanced accuracies, robustness of these algorithms against attacks and bias has been challenged. This paper summarizes different ways in which the robustness of a face recognition algorithm is challenged, which can severely affect its intended working. Different types of attacks such as physical presentation attacks, disguise/makeup, digital adversarial attacks, and morphing/tampering using GANs have been discussed. We also present a discussion on the effect of bias on face recognition models and showcase that factors such as age and gender variations affect the performance of modern algorithms. The paper also presents the potential reasons for these challenges and some of the future research directions for increasing the robustness of face recognition models.},
archivePrefix = {arXiv},
arxivId = {2002.02942},
author = {Singh, Richa and Agarwal, Akshay and Singh, Maneet and Nagpal, Shruti and Vatsa, Mayank},
doi = {10.1609/aaai.v34i09.7085},
eprint = {2002.02942},
file = {:C$\backslash$:/Users/zeera/Downloads/2002.02942.pdf:pdf},
issn = {2374-3468},
title = {{On the Robustness of Face Recognition Algorithms Against Attacks and Bias}},
url = {http://arxiv.org/abs/2002.02942},
year = {2020}
}
@article{Deng2019,
abstract = {Though tremendous strides have been made in uncontrolled face detection, accurate and efficient face localisation in the wild remains an open challenge. This paper presents a robust single-stage face detector, named RetinaFace, which performs pixel-wise face localisation on various scales of faces by taking advantages of joint extra-supervised and self-supervised multi-task learning. Specifically, We make contributions in the following five aspects: (1) We manually annotate five facial landmarks on the WIDER FACE dataset and observe significant improvement in hard face detection with the assistance of this extra supervision signal. (2) We further add a self-supervised mesh decoder branch for predicting a pixel-wise 3D shape face information in parallel with the existing supervised branches. (3) On the WIDER FACE hard test set, RetinaFace outperforms the state of the art average precision (AP) by 1.1{\%} (achieving AP equal to 91.4{\%}). (4) On the IJB-C test set, RetinaFace enables state of the art methods (ArcFace) to improve their results in face verification (TAR=89.59{\%} for FAR=1e-6). (5) By employing light-weight backbone networks, RetinaFace can run real-time on a single CPU core for a VGA-resolution image. Extra annotations and code have been made available at: https://github.com/deepinsight/insightface/tree/master/RetinaFace.},
archivePrefix = {arXiv},
arxivId = {1905.00641},
author = {Deng, Jiankang and Guo, Jia and Zhou, Yuxiang and Yu, Jinke and Kotsia, Irene and Zafeiriou, Stefanos},
eprint = {1905.00641},
file = {:C$\backslash$:/Users/zeera/Downloads/1905.00641.pdf:pdf},
title = {{RetinaFace: Single-stage Dense Face Localisation in the Wild}},
url = {http://arxiv.org/abs/1905.00641},
year = {2019}
}
@article{Zhang2016,
abstract = {Face detection and alignment in unconstrained environment are challenging due to various poses, illuminations, and occlusions. Recent studies show that deep learning approaches can achieve impressive performance on these two tasks. In this letter, we propose a deep cascaded multitask framework that exploits the inherent correlation between detection and alignment to boost up their performance. In particular, our framework leverages a cascaded architecture with three stages of carefully designed deep convolutional networks to predict face and landmark location in a coarse-to-fine manner. In addition, we propose a new online hard sample mining strategy that further improves the performance in practice. Our method achieves superior accuracy over the state-of-the-art techniques on the challenging face detection dataset and benchmark and WIDER FACE benchmarks for face detection, and annotated facial landmarks in the wild benchmark for face alignment, while keeps real-time performance.},
archivePrefix = {arXiv},
arxivId = {1604.02878},
author = {Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
doi = {10.1109/LSP.2016.2603342},
eprint = {1604.02878},
file = {:C$\backslash$:/Users/zeera/Downloads/1604.02878.pdf:pdf},
issn = {10709908},
journal = {IEEE Signal Processing Letters},
keywords = {Cascaded convolutional neural network (CNN),face alignment,face detection},
number = {10},
pages = {1499--1503},
title = {{Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks}},
volume = {23},
year = {2016}
}
@article{Dalal2005,
abstract = {We study the question of feature sets for robust visual object recognition, adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of Histograms of Oriented Gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds. {\textcopyright} 2005 IEEE.},
author = {Dalal, Navneet and Triggs, Bill},
doi = {10.1109/CVPR.2005.177},
file = {:C$\backslash$:/Users/zeera/Downloads/01467360.pdf:pdf},
isbn = {0769523722},
journal = {Proceedings - 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2005},
pages = {886--893},
title = {{Histograms of oriented gradients for human detection}},
volume = {I},
year = {2005}
}
