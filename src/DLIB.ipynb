{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLIB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkM-uFCmXrVM"
      },
      "source": [
        "File Structure as follows on Google Collab:\n",
        "\n",
        "\n",
        "\n",
        "*   content/\n",
        "  *   shape_predictor_68_face_landmarks.dat\n",
        "  *   {48 photos from 5025 dataset}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHq7W9gq0CJj"
      },
      "source": [
        "Implementation heavily influenced from Adrian Rosebrock's blog, Facial landmarks with dlib, OpenCV, and Python:\n",
        "https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhU-hFzaoIhP"
      },
      "source": [
        "#Import necessary packages\n",
        "from imutils import face_utils\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import os\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM0LVdvfzAhl"
      },
      "source": [
        "#Download 68 point predictor pre-trained with i-BUG Dataset\n",
        "!wget -nd https://github.com/JeffTrain/selfie/raw/master/shape_predictor_68_face_landmarks.dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SopvtLA5vMXH"
      },
      "source": [
        "dlib_annotation={}\n",
        "#Instantiate the HOG detector from the DLIB library\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "#Instantiate the dlib predictor with the 68 point predictor\n",
        "shape_predictor = \"/content/shape_predictor_68_face_landmarks.dat\"\n",
        "predictor = dlib.shape_predictor(shape_predictor)\n",
        "#Iterate through images extracting ID from label\n",
        "for filename in os.listdir(\"/content/\"):\n",
        "  if filename.endswith(\".jpg\"):\n",
        "    if (filename.split(\"_\")[0][0] == '0'):\n",
        "      id = int(filename.split(\"_\")[0][1])\n",
        "    else:\n",
        "      id = int(filename.split(\"_\")[0])\n",
        "\n",
        "    bb={}\n",
        "    lm={}\n",
        "\n",
        "    #Import image in BGR colour mode and convert to grayscale image\n",
        "    image = cv2.imread(\"/content/\"+filename)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    #Call the HOG face detector to output bounding boxes for the image \n",
        "    rects = detector(gray, 1)\n",
        "    #Call the 68 point predictor on the image and its bounding box\n",
        "    shape = predictor(gray, rects[0])\n",
        "    #Covert shape object to numpy array for easier manipulation\n",
        "    shape = face_utils.shape_to_np(shape)\n",
        "\n",
        "    #Calculate left eye landmark using the point between a line connecting the edge eye landmarks\n",
        "    left_eye_x = (float(shape[36][0]) + float(shape[39][0]))/2\n",
        "    left_eye_y = (float(shape[36][1]) + float(shape[39][1]))/2\n",
        "    left_eye = [left_eye_x,left_eye_y]\n",
        "    #Calculate right eye landmark using the point between a line connecting the edge eye landmarks\n",
        "    right_eye_x = (float(shape[42][0]) + float(shape[45][0]))/2\n",
        "    right_eye_y = (float(shape[42][1]) + float(shape[45][1]))/2\n",
        "    right_eye = [right_eye_x,right_eye_y]\n",
        "    #Extract nose landmark from 68 points\n",
        "    nose = [float(shape[30][0]),float(shape[30][1])]\n",
        "    #Extract mouth landmarks from\n",
        "    left_mouth = [float(shape[48][0]),float(shape[48][1])]\n",
        "    right_mouth = [float(shape[54][0]),float(shape[54][1])]\n",
        "    #Extract bounding box values from rect object\n",
        "    (x, y, w, h) = face_utils.rect_to_bb(rects[0])\n",
        "    #Show bounding box and 68 point landmark coordinates on face\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "    for (x, y) in shape:\n",
        "      cv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
        "    cv2_imshow(image)\n",
        "    #Add bounding box and landmark coordinates to dictionary for every face id\n",
        "    bb = {\"x\":float(x),\"y\":float(y),\"w\":float(w),\"h\":float(h)}\n",
        "    lm ={'left_eye': left_eye, 'right_eye': right_eye, 'nose': nose, 'left_mouth': left_mouth, 'right_mouth': right_mouth}\n",
        "    dlib_annotation[id]={\"bounding_box\":bb,\"landmarks\":lm}\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbt6xifC10RN"
      },
      "source": [
        "#Export dictionary as JSON file for further analysis\n",
        "json = json.dumps(dlib_annotation)\n",
        "f = open(\"dlib_annotated.json\",\"w\")\n",
        "f.write(json)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}