{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ViolaJones.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lMwmjhcYdUW"
      },
      "source": [
        "File Structure as follows on Google Collab:\n",
        "\n",
        "\n",
        "\n",
        "*   content/\n",
        "  *   {48 photos from 5025 dataset}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO-HdX7VfN1c"
      },
      "source": [
        "# Import necessary packages\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import dlib\n",
        "from imutils import face_utils\n",
        "import os\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UAceETKfYM5"
      },
      "source": [
        "#Instantiate the face haar cascade classifier from the OpenCV library\n",
        "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1BgK9q0hJHn"
      },
      "source": [
        "violajones_annotations={}\n",
        "#Iterate through content folder and extract id from images labels\n",
        "for filename in os.listdir(\"/content/\"):\n",
        "  if filename.endswith(\".jpg\"):\n",
        "    if (filename.split(\"_\")[0][0] == '0'):\n",
        "      id = int(filename.split(\"_\")[0][1])\n",
        "    else:\n",
        "      id = int(filename.split(\"_\")[0])\n",
        "    bb={}\n",
        "    #Import image in BGR colour mode and convert to grayscale image\n",
        "    image = cv2.imread(\"/content/\"+filename)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    #Run classifier against image to detect faces\n",
        "    faces = faceCascade.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "    count = 0\n",
        "    #Iterate through faces detected\n",
        "    for (x, y, w, h) in faces: \n",
        "        # Draw rectangle around the face\n",
        "        cv2.rectangle(gray, (x, y), (x+w, y+h), (255, 255, 255), 3)\n",
        "        cv2_imshow(gray) \n",
        "        #Add bounding boxes coordinates to dictionary for each face\n",
        "        bb[count]={\"x\":float(x),\"y\":float(y),\"w\":float(w),\"h\":float(h)}\n",
        "        count = count +1\n",
        "    #Store bounding boxes dictionary into dictionary for each image id\n",
        "    violajones_annotations[id]=bb\n",
        "    \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d4i3MUX71gJ"
      },
      "source": [
        "#Export dictionary as JSON file for further analysis\n",
        "json = json.dumps(violajones_annotations)\n",
        "f = open(\"violajones_annotated.json\",\"w\")\n",
        "f.write(json)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}