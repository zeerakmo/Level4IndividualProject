{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RetinaFace",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFGVFxdMTx3E"
      },
      "source": [
        "File Structure as follows on Google Collab:\n",
        "\n",
        "*   content/\n",
        "  *   {48 photos from 5025 dataset}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTzppfcuBOb8"
      },
      "source": [
        "Implementation heavily influenced from Vladimir Iglovikov's pytorch implementation, retinaface: \n",
        "\n",
        "https://github.com/ternaus/retinaface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPvRja86__YH"
      },
      "source": [
        "Download the two packages below and restart the runtime as prompted in the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maHSaXSq_-8F"
      },
      "source": [
        "!pip install -U ipykernel\n",
        "!pip install modin[dask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81D52HKGAKln"
      },
      "source": [
        "After runtime has been restarted, install retinaface_pytorch package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u140zXvUUz0r"
      },
      "source": [
        "!pip install -U retinaface_pytorch > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AebSwGm0ZUPM"
      },
      "source": [
        "#Import necessary packages\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import json\n",
        "from matplotlib import pyplot as plt\n",
        "from retinaface.pre_trained_models import get_model\n",
        "from retinaface.utils import vis_annotations\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzCjM8qDbgyk"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (15, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncKpxhI-TlM3"
      },
      "source": [
        "#Instantiate the pretrained retinface model\n",
        "model = get_model(\"resnet50_2020-07-20\", max_size=(300))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0skaQEV_g4UC"
      },
      "source": [
        "\n",
        "RetinaNet_annotated = {}\n",
        "#Iterate through images and extract ID\n",
        "for filename in os.listdir(\"/content/\"):\n",
        "  if filename.endswith(\".jpg\"):\n",
        "    if (filename.split(\"_\")[0][0] == '0'):\n",
        "      id = int(filename.split(\"_\")[0][1])\n",
        "    else:\n",
        "      id = int(filename.split(\"_\")[0])\n",
        "\n",
        "    #Import image in BGR colour mode and conver to RGB colour mode \n",
        "    img = cv2.imread(filename)\n",
        "    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    \n",
        "    #Call the prediction function of the model to output predictions for image\n",
        "    annotation = model.predict_jsons(image)\n",
        "    annotation = annotation[0]\n",
        "    #Display the bounding box and landmarks on face\n",
        "    x = (annotation[\"bbox\"][0])\n",
        "    y = (annotation[\"bbox\"][1])\n",
        "    w = (annotation[\"bbox\"][2])-(annotation[\"bbox\"][0])\n",
        "    h = (annotation[\"bbox\"][3])-(annotation[\"bbox\"][1])\n",
        "    # print(x,y,w,h)\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), 3)\n",
        "    for x in annotation[\"landmarks\"]:\n",
        "      cv2.circle(img, (x[0], x[1]), 1, (0, 0, 255), -1)\n",
        "    cv2_imshow(img) \n",
        "    bb = {}\n",
        "    lm = {}\n",
        "    #Place x,y,w,h bounding box values in dictionary\n",
        "    bb = {\"x\":float(annotation[\"bbox\"][0]),\"y\":float(annotation[\"bbox\"][1]),\"w\":float(annotation[\"bbox\"][2])-float(annotation[\"bbox\"][0]),\"h\":float(annotation[\"bbox\"][3])-float(annotation[\"bbox\"][1])}\n",
        "    #Place landmark coordinates in dictionary\n",
        "    lm ={'left_eye': annotation[\"landmarks\"][0], 'right_eye': annotation[\"landmarks\"][1], 'nose': annotation[\"landmarks\"][2], 'left_mouth': annotation[\"landmarks\"][3], 'right_mouth': annotation[\"landmarks\"][4]}\n",
        "    #Add bounding box and landmark coordinates to dictionary for every face id\n",
        "    RetinaNet_annotated[id]={\"bounding_box\":bb,\"landmarks\":lm}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U261lgr0pnYG"
      },
      "source": [
        "#Export dictionary as JSON file for further analysis\n",
        "json = json.dumps(RetinaNet_annotated)\n",
        "f = open(\"retinaface_annotated.json\",\"w\")\n",
        "f.write(json)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}